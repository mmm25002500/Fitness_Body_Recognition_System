"""
Fitness AI Trainer - Streamlit Web æ‡‰ç”¨
æ•´åˆé‹å‹•è¾¨è­˜ã€è¨ˆæ•¸ã€è¦–è¦ºåŒ–åŠŸèƒ½
"""
import streamlit as st
import cv2
import numpy as np
import tempfile
import os
from pathlib import Path

# ç¢ºä¿ä½¿ç”¨ MediaPipe
os.environ["PREFER_MEDIAPIPE"] = "1"

from pose_config import get_pose_extractor
from test import BiLSTMAttention
from exercise_counter import RepetitionCounter
from visualization import PoseVisualizer
import torch


class FitnessAITrainer:
    """å¥èº« AI è¨“ç·´ç³»çµ±"""

    def __init__(self, model_path="bilstm_mix_best_pt.pth"):
        """åˆå§‹åŒ–ç³»çµ±"""
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        # è¼‰å…¥æ¨¡å‹
        self.model = BiLSTMAttention(
            input_dim=102,
            hidden_dim=96,
            attn_dim=128,
            num_classes=5
        ).to(self.device)
        self.model.load_state_dict(torch.load(model_path, map_location=self.device))
        self.model.eval()

        # åˆå§‹åŒ–æ¨¡çµ„
        self.pose_extractor = get_pose_extractor(prefer_mediapipe=True)
        self.visualizer = PoseVisualizer()

        # é¡åˆ¥åç¨±
        self.class_names = [
            "æ§“éˆ´äºŒé ­å½èˆ‰",
            "éŒ˜å¼å½èˆ‰",
            "ä¼åœ°æŒºèº«",
            "è‚©ä¸Šæ¨èˆ‰",
            "æ·±è¹²"
        ]

        # æ»‘å‹•çª—å£
        self.window_size = 45
        self.feature_buffer = []
        self.current_exercise = None
        self.counter = None

    def extract_features(self, landmarks):
        """å¾ landmarks æå– 102 ç¶­ç‰¹å¾µ"""
        if landmarks is None:
            return None

        features = []

        # 1. 8å€‹é—œç¯€è§’åº¦
        angles = self._calculate_joint_angles(landmarks)
        features.extend(angles)

        # 2. 17å€‹é—œéµé»çš„ 3D åº§æ¨™ (51 å€‹å€¼)
        key_points_idx = [0, 11, 12, 13, 14, 15, 16, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]
        for idx in key_points_idx:
            features.extend(landmarks[idx][:3])  # x, y, z

        # 3. å¹¾ä½•ç‰¹å¾µ (43 å€‹å€¼)
        geometric = self._calculate_geometric_features(landmarks)
        features.extend(geometric)

        return np.array(features, dtype=np.float32)

    def _calculate_joint_angles(self, landmarks):
        """è¨ˆç®—8å€‹é—œç¯€è§’åº¦"""
        def angle_3d(a, b, c):
            ba = a - b
            bc = c - b
            cosine = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc) + 1e-6)
            return np.arccos(np.clip(cosine, -1.0, 1.0))

        angles = []
        # å·¦å³æ‰‹è‚˜ã€è‚©è†€ã€è†è“‹ã€é«–éƒ¨
        joints = [
            (11, 13, 15), (12, 14, 16),  # å·¦å³æ‰‹è‚˜
            (13, 11, 23), (14, 12, 24),  # å·¦å³è‚©è†€
            (23, 25, 27), (24, 26, 28),  # å·¦å³è†è“‹
            (11, 23, 25), (12, 24, 26),  # å·¦å³é«–éƒ¨
        ]

        for a_idx, b_idx, c_idx in joints:
            a = landmarks[a_idx][:3]
            b = landmarks[b_idx][:3]
            c = landmarks[c_idx][:3]
            angles.append(angle_3d(a, b, c))

        return angles

    def _calculate_geometric_features(self, landmarks):
        """è¨ˆç®—å¹¾ä½•ç‰¹å¾µ"""
        features = []

        # èº«é«”ä¸­å¿ƒé»
        center = (landmarks[11][:3] + landmarks[12][:3]) / 2

        # è¨ˆç®—ç›¸å°æ–¼ä¸­å¿ƒçš„è·é›¢å’Œè§’åº¦
        key_points = [0, 15, 16, 23, 24, 27, 28]
        for idx in key_points:
            diff = landmarks[idx][:3] - center
            dist = np.linalg.norm(diff)
            features.append(dist)
            features.extend(diff)  # x, y, z å·®å€¼

        # è‚¢é«”é•·åº¦æ¯”ä¾‹
        torso_length = np.linalg.norm(landmarks[11][:3] - landmarks[23][:3])
        left_arm = np.linalg.norm(landmarks[11][:3] - landmarks[15][:3])
        right_arm = np.linalg.norm(landmarks[12][:3] - landmarks[16][:3])
        left_leg = np.linalg.norm(landmarks[23][:3] - landmarks[27][:3])
        right_leg = np.linalg.norm(landmarks[24][:3] - landmarks[28][:3])

        features.extend([torso_length, left_arm, right_arm, left_leg, right_leg])

        # å¡«å……åˆ° 43 ç¶­
        while len(features) < 43:
            features.append(0.0)

        return features[:43]

    def predict_exercise(self, features_sequence):
        """é æ¸¬é‹å‹•é¡å‹"""
        if len(features_sequence) < self.window_size:
            return None, None

        # å–æœ€å¾Œ 45 å¹€
        sequence = np.array(features_sequence[-self.window_size:])

        # Z-score æ­£è¦åŒ–
        mean = sequence.mean(axis=0)
        std = sequence.std(axis=0) + 1e-6
        sequence = (sequence - mean) / std

        # è½‰æ›ç‚º tensor
        sequence_tensor = torch.FloatTensor(sequence).unsqueeze(0).to(self.device)

        # é æ¸¬
        with torch.no_grad():
            output = self.model(sequence_tensor)
            probabilities = torch.softmax(output, dim=1).cpu().numpy()[0]

        predicted_class = np.argmax(probabilities)
        confidence = probabilities[predicted_class] * 100

        return predicted_class, probabilities

    def process_frame(self, frame, mode="automatic", debug=False):
        """
        è™•ç†å–®å¹€å½±åƒ

        Args:
            frame: BGR å½±åƒ
            mode: "automatic" è‡ªå‹•æ¨¡å¼ï¼Œ"manual" æ‰‹å‹•æ¨¡å¼
            debug: æ˜¯å¦å•Ÿç”¨é™¤éŒ¯æ¨¡å¼

        Returns:
            è™•ç†å¾Œçš„å½±åƒ
        """
        # å§¿æ…‹ä¼°è¨ˆ
        landmarks, pose_landmarks = self.pose_extractor.extract_landmarks(frame)

        if landmarks is None:
            self.visualizer.draw_instructions(frame, "æœªåµæ¸¬åˆ°äººç‰©ï¼Œè«‹ç¢ºä¿å…¨èº«åœ¨ç•«é¢ä¸­")
            return frame

        # ç¹ªè£½éª¨æ¶
        frame = self.visualizer.draw_landmarks(frame, pose_landmarks)

        # æå–ç‰¹å¾µ
        features = self.extract_features(landmarks)
        if features is not None:
            self.feature_buffer.append(features)

            # è‡ªå‹•æ¨¡å¼ï¼šé‹å‹•è¾¨è­˜
            if mode == "automatic" and len(self.feature_buffer) >= self.window_size:
                predicted_id, probabilities = self.predict_exercise(self.feature_buffer)

                if predicted_id is not None:
                    # æª¢æŸ¥æ˜¯å¦éœ€è¦å‰µå»ºæˆ–æ›´æ–°è¨ˆæ•¸å™¨
                    need_new_counter = False

                    if self.counter is None:
                        need_new_counter = True
                    elif self.current_exercise != predicted_id:
                        # é‹å‹•é¡å‹æ”¹è®Šï¼Œéœ€è¦æ–°è¨ˆæ•¸å™¨
                        need_new_counter = True

                    if need_new_counter:
                        self.current_exercise = predicted_id
                        self.counter = RepetitionCounter(self.class_names[predicted_id])
                        self.counter.debug = debug

                    # æ›´æ–°é™¤éŒ¯æ¨¡å¼
                    self.counter.debug = debug

                    # æ›´æ–°è¨ˆæ•¸
                    counter_result = self.counter.update(landmarks, predicted_id)

                    # ç¹ªè£½è³‡è¨Š
                    frame = self.visualizer.draw_counter_info(
                        frame,
                        self.class_names[predicted_id],
                        counter_result["count"],
                        counter_result["stage"],
                        probabilities[predicted_id] * 100
                    )

                    # ç¹ªè£½è§’åº¦
                    if counter_result["angle"] is not None and counter_result["points"] is not None:
                        _, point_b, _ = counter_result["points"]
                        frame = self.visualizer.draw_angle(
                            frame,
                            counter_result["angle"],
                            point_b
                        )

                    # ç¹ªè£½é æ¸¬æ©Ÿç‡æ¢
                    frame = self.visualizer.draw_prediction_bar(
                        frame,
                        self.class_names,
                        probabilities
                    )

            # æ‰‹å‹•æ¨¡å¼ï¼šä½¿ç”¨è€…é¸æ“‡é‹å‹•
            elif mode == "manual" and self.current_exercise is not None:
                counter_result = self.counter.update(landmarks, self.current_exercise)

                frame = self.visualizer.draw_counter_info(
                    frame,
                    self.class_names[self.current_exercise],
                    counter_result["count"],
                    counter_result["stage"]
                )

                if counter_result["angle"] is not None and counter_result["points"] is not None:
                    _, point_b, _ = counter_result["points"]
                    frame = self.visualizer.draw_angle(
                        frame,
                        counter_result["angle"],
                        point_b
                    )

        return frame

    def reset(self):
        """é‡ç½®ç³»çµ±ç‹€æ…‹"""
        self.feature_buffer = []
        self.current_exercise = None
        self.counter = None


def main():
    """Streamlit ä¸»æ‡‰ç”¨"""
    st.set_page_config(
        page_title="Fitness AI Trainer",
        page_icon="ğŸ’ª",
        layout="wide"
    )

    st.title("ğŸ’ª Fitness AI Trainer - é‹å‹•è¾¨è­˜èˆ‡è¨ˆæ•¸ç³»çµ±")
    st.markdown("---")

    # åˆå§‹åŒ–ç³»çµ±
    if "trainer" not in st.session_state:
        with st.spinner("è¼‰å…¥ AI æ¨¡å‹ä¸­..."):
            st.session_state.trainer = FitnessAITrainer()
        st.success("âœ“ AI æ¨¡å‹è¼‰å…¥å®Œæˆï¼")

    trainer = st.session_state.trainer

    # åˆå§‹åŒ–è¨ˆæ•¸å™¨ç‹€æ…‹ï¼ˆä½¿ç”¨ session_state ä¿å­˜è¨ˆæ•¸å™¨ï¼‰
    if "current_counter" not in st.session_state:
        st.session_state.current_counter = None
    if "last_exercise" not in st.session_state:
        st.session_state.last_exercise = None
    if "last_mode" not in st.session_state:
        st.session_state.last_mode = None

    # å´é‚Šæ¬„è¨­å®š
    st.sidebar.header("âš™ï¸ è¨­å®š")

    mode = st.sidebar.radio(
        "é¸æ“‡æ¨¡å¼",
        ["automatic", "manual"],
        format_func=lambda x: "ğŸ¤– è‡ªå‹•æ¨¡å¼ï¼ˆAI è¾¨è­˜ï¼‰" if x == "automatic" else "âœ‹ æ‰‹å‹•æ¨¡å¼ï¼ˆæ‰‹å‹•é¸æ“‡ï¼‰"
    )

    # é™¤éŒ¯æ¨¡å¼
    debug_mode = st.sidebar.checkbox("ğŸ› é™¤éŒ¯æ¨¡å¼ï¼ˆé¡¯ç¤ºè§’åº¦è³‡è¨Šï¼‰", value=False)

    # æ‰‹å‹•æ¨¡å¼ä¸‹é¸æ“‡é‹å‹•
    if mode == "manual":
        exercise_choice = st.sidebar.selectbox(
            "é¸æ“‡é‹å‹•é¡å‹",
            range(5),
            format_func=lambda x: trainer.class_names[x]
        )

        # åªåœ¨é‹å‹•é¡å‹æˆ–æ¨¡å¼æ”¹è®Šæ™‚é‡æ–°å‰µå»ºè¨ˆæ•¸å™¨
        if (st.session_state.last_exercise != exercise_choice or
            st.session_state.last_mode != mode or
            st.session_state.current_counter is None):

            st.session_state.last_exercise = exercise_choice
            st.session_state.last_mode = mode
            st.session_state.current_counter = RepetitionCounter(trainer.class_names[exercise_choice])
            st.session_state.current_counter.debug = debug_mode

        # å¾ session_state æ¢å¾©è¨ˆæ•¸å™¨
        trainer.current_exercise = exercise_choice
        trainer.counter = st.session_state.current_counter

        # æ›´æ–°é™¤éŒ¯æ¨¡å¼
        if trainer.counter is not None:
            trainer.counter.debug = debug_mode

    # è‡ªå‹•æ¨¡å¼ï¼šæº–å‚™è¨ˆæ•¸å™¨ï¼ˆä½†ä¸æŒ‡å®šé‹å‹•é¡å‹ï¼‰
    else:
        # å¦‚æœæ¨¡å¼æ”¹è®Šï¼Œé‡ç½®è¨ˆæ•¸å™¨
        if st.session_state.last_mode != mode:
            st.session_state.last_mode = mode
            st.session_state.current_counter = None
            st.session_state.last_exercise = None

    input_type = st.sidebar.radio(
        "é¸æ“‡è¼¸å…¥ä¾†æº",
        ["video", "webcam"],
        format_func=lambda x: "ğŸ“¹ å½±ç‰‡æª”æ¡ˆ" if x == "video" else "ğŸ“· å³æ™‚æ”å½±æ©Ÿ"
    )

    # é‡ç½®æŒ‰éˆ•
    if st.sidebar.button("ğŸ”„ é‡ç½®è¨ˆæ•¸å™¨"):
        # é‡ç½® session_state ä¸­çš„è¨ˆæ•¸å™¨
        st.session_state.current_counter = None
        st.session_state.last_exercise = None
        st.session_state.last_mode = None
        trainer.reset()
        st.sidebar.success("è¨ˆæ•¸å™¨å·²é‡ç½®ï¼")
        st.rerun()

    # å½±ç‰‡ä¸Šå‚³æ¨¡å¼
    if input_type == "video":
        st.sidebar.markdown("---")
        st.sidebar.info("ğŸ“¤ è«‹ä¸Šå‚³é‹å‹•å½±ç‰‡ï¼ˆæ”¯æ´ mp4, avi, movï¼‰")

        uploaded_file = st.file_uploader(
            "é¸æ“‡å½±ç‰‡æª”æ¡ˆ",
            type=["mp4", "avi", "mov"]
        )

        if uploaded_file is not None:
            # å„²å­˜æš«å­˜æª”æ¡ˆ
            tfile = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
            tfile.write(uploaded_file.read())
            video_path = tfile.name

            st.markdown("### ğŸ“Š åˆ†æçµæœ")

            # å½±ç‰‡è³‡è¨Š
            cap = cv2.VideoCapture(video_path)
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            fps = int(cap.get(cv2.CAP_PROP_FPS))
            duration = total_frames / fps if fps > 0 else 0

            col1, col2, col3 = st.columns(3)
            col1.metric("ç¸½å¹€æ•¸", f"{total_frames} å¹€")
            col2.metric("FPS", f"{fps}")
            col3.metric("é•·åº¦", f"{duration:.1f} ç§’")

            # è™•ç†å½±ç‰‡
            stframe = st.empty()
            progress_bar = st.progress(0)
            status_text = st.empty()

            frame_count = 0
            # ä¸è¦é‡ç½®ï¼Œä¿ç•™ session_state ä¸­çš„è¨ˆæ•¸å™¨
            # åªé‡ç½®ç‰¹å¾µç·©è¡å€
            trainer.feature_buffer = []

            # ç¢ºä¿ä½¿ç”¨ session_state çš„è¨ˆæ•¸å™¨
            if st.session_state.current_counter is not None:
                trainer.counter = st.session_state.current_counter

            while cap.isOpened():
                ret, frame = cap.read()
                if not ret:
                    break

                # åœ¨è™•ç†å‰ï¼Œå…ˆå¾ session_state æ¢å¾©è¨ˆæ•¸å™¨
                if st.session_state.current_counter is not None:
                    trainer.counter = st.session_state.current_counter

                # è™•ç†å¹€
                processed_frame = trainer.process_frame(frame, mode=mode, debug=debug_mode)

                # è™•ç†å¾Œï¼ŒåŒæ­¥è¨ˆæ•¸å™¨å› session_stateï¼ˆé‡è¦ï¼ï¼‰
                if trainer.counter is not None:
                    st.session_state.current_counter = trainer.counter
                    # åŒæ™‚æ›´æ–°é‹å‹•é¡å‹è¨˜éŒ„ï¼ˆè‡ªå‹•æ¨¡å¼ï¼‰
                    if mode == "automatic" and trainer.current_exercise is not None:
                        st.session_state.last_exercise = trainer.current_exercise

                # é¡¯ç¤º
                processed_frame_rgb = cv2.cvtColor(processed_frame, cv2.COLOR_BGR2RGB)
                stframe.image(processed_frame_rgb, channels="RGB", use_column_width=True)

                # æ›´æ–°é€²åº¦
                frame_count += 1
                progress = frame_count / total_frames
                progress_bar.progress(progress)
                status_text.text(f"è™•ç†ä¸­... {frame_count}/{total_frames} å¹€ ({progress*100:.1f}%)")

            cap.release()
            os.unlink(video_path)

            st.success("âœ“ å½±ç‰‡è™•ç†å®Œæˆï¼")

            # é¡¯ç¤ºæœ€çµ‚çµ±è¨ˆ
            if st.session_state.current_counter is not None:
                st.markdown("### ğŸ“ˆ çµ±è¨ˆçµæœ")
                final_count = st.session_state.current_counter.count
                st.metric("ç¸½æ¬¡æ•¸", final_count, delta=None)

                # é¡¯ç¤ºè©³ç´°è³‡è¨Š
                col1, col2, col3 = st.columns(3)
                col1.metric("é‹å‹•é¡å‹", trainer.class_names[st.session_state.last_exercise])
                col2.metric("ç¸½æ¬¡æ•¸", final_count)
                col3.metric("è™•ç†å¹€æ•¸", frame_count)

    # å³æ™‚æ”å½±æ©Ÿæ¨¡å¼
    else:
        st.info("ğŸ“· å³æ™‚æ”å½±æ©Ÿæ¨¡å¼")
        st.warning("âš ï¸ æ­¤åŠŸèƒ½éœ€è¦åœ¨æœ¬åœ°é‹è¡Œ Streamlit æ‰èƒ½ä½¿ç”¨æ”å½±æ©Ÿ")
        st.markdown("""
        è«‹åœ¨çµ‚ç«¯æ©ŸåŸ·è¡Œï¼š
        ```bash
        source venv_mediapipe/bin/activate
        streamlit run app.py
        ```
        ç„¶å¾Œåœ¨ç€è¦½å™¨ä¸­å…è¨±æ”å½±æ©Ÿæ¬Šé™ã€‚
        """)

        run_webcam = st.checkbox("å•Ÿå‹•æ”å½±æ©Ÿ")

        if run_webcam:
            cap = cv2.VideoCapture(0)
            stframe = st.empty()
            stop_button = st.button("åœæ­¢")

            trainer.reset()

            while cap.isOpened() and not stop_button:
                ret, frame = cap.read()
                if not ret:
                    st.error("ç„¡æ³•è®€å–æ”å½±æ©Ÿ")
                    break

                # è™•ç†å¹€
                processed_frame = trainer.process_frame(frame, mode=mode, debug=debug_mode)

                # é¡¯ç¤º
                processed_frame_rgb = cv2.cvtColor(processed_frame, cv2.COLOR_BGR2RGB)
                stframe.image(processed_frame_rgb, channels="RGB", use_column_width=True)

            cap.release()

    # èªªæ˜æ–‡ä»¶
    with st.expander("ğŸ“– ä½¿ç”¨èªªæ˜"):
        st.markdown("""
        ## åŠŸèƒ½èªªæ˜

        ### ğŸ¤– è‡ªå‹•æ¨¡å¼
        - AI è‡ªå‹•è¾¨è­˜é‹å‹•é¡å‹
        - è‡ªå‹•è¨ˆç®—æ¬¡æ•¸
        - é¡¯ç¤ºé æ¸¬ä¿¡å¿ƒåº¦å’Œå„é¡åˆ¥æ©Ÿç‡

        ### âœ‹ æ‰‹å‹•æ¨¡å¼
        - æ‰‹å‹•é¸æ“‡é‹å‹•é¡å‹
        - è‡ªå‹•è¨ˆç®—æ¬¡æ•¸
        - é©åˆå°ˆæ³¨è¨“ç·´ç‰¹å®šå‹•ä½œ

        ### æ”¯æ´çš„é‹å‹•
        1. æ§“éˆ´äºŒé ­å½èˆ‰ (Barbell Biceps Curl)
        2. éŒ˜å¼å½èˆ‰ (Hammer Curl)
        3. ä¼åœ°æŒºèº« (Push-up)
        4. è‚©ä¸Šæ¨èˆ‰ (Shoulder Press)
        5. æ·±è¹² (Squat)

        ### ä½¿ç”¨æŠ€å·§
        - ç¢ºä¿å…¨èº«åœ¨ç•«é¢ä¸­
        - ä¿æŒè‰¯å¥½çš„å…‰ç·š
        - å‹•ä½œå®Œæ•´æ¸…æ™°
        - é¿å…å¿«é€Ÿç§»å‹•é€ æˆæ¨¡ç³Š
        """)


if __name__ == "__main__":
    main()
